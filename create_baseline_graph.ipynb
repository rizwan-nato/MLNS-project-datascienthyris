{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import shutil\n",
    "import scipy.stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top-level directories:\n",
    "\n",
    " edf/dev/01_tcp_ar\n",
    " edf/dev/02_tcp_le\n",
    " edf/dev/03_tcp_ar_a\n",
    " edf/train/01_tcp_ar\n",
    " edf/train/02_tcp_le\n",
    " edf/train/03_tcp_ar_a\n",
    "\n",
    "refer to the appropriate channel configurations for the\n",
    "EEGs. 01_tcp_ar refers to an AR reference configuration, with\n",
    "annotations referencing a TCP format described below.\n",
    "\n",
    "The pathname of a typical EEG file can be explained as follows:\n",
    "\n",
    " Filename:\n",
    "  edf/dev_test/01_tcp_ar/002/00000258/s002_2003_07_21/00000258_s002_t000.edf\n",
    "\n",
    " Components:\n",
    "  edf: contains the edf data\n",
    "\n",
    "  dev_test: part of the dev_test set (vs.) train\n",
    "\n",
    "  01_tcp_ar: data that follows the averaged reference (AR) configuration,\n",
    "             while annotations use the TCP channel configutation\n",
    "\n",
    "  002: a three-digit identifier meant to keep the number of subdirectories\n",
    "       in a directory manageable. This follows the TUH EEG v1.1.0 convention.\n",
    "\n",
    "  00000258: official patient number that is linked to v1.1.0 of TUH EEG\n",
    "\n",
    "  s002_2003_07_21: session two (s002) for this patient. The session\n",
    "                   was archived on 07/21/2003.\n",
    "\n",
    "  00000258_s002_t000.edf: the actual EEG file. These are split into a series of\n",
    "  \t\t\t  files starting with t000.edf, t001.edf, ... These\n",
    "\t\t\t  represent pruned EEGs, so the original EEG is \n",
    "\t\t\t  split into these segments, and uninteresting\n",
    "\t\t\t  parts of the original recording were deleted\n",
    "\t\t\t  (common in clinical practice).\n",
    "\n",
    "The easiest way to access the annotations is through the spreadsheet\n",
    "provided (_SEIZURES_*.xlsx). This contains the start and stop time\n",
    "of each seizure event in an easy to understand format. Convert the\n",
    "file to .csv if you need a machine-readable version.\n",
    "\n",
    "There are six types of files in this release:\n",
    "\n",
    " *.edf:    the EEG sampled data in European Data Format (edf)\n",
    " *.txt:    the EEG report corresponding to the patient and session\n",
    " *.tse:    term-based annotations using all available seizure type classes\n",
    " *.tse_bi: same as *.tse except bi-class annotations (seizure/background) \n",
    " *.lbl:    event-based annotations using all available seizure type classes\n",
    " *.lbl_bi: same as *.lbl except bi-class annotations (seizure/background)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(os.getcwd(), \"data\")\n",
    "RESAMPLE_RATE = 128 #Hz\n",
    "SLIDING_WINDOW = 1 #s\n",
    "MAX_SEQUENCE_LENGTH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_train = pd.read_excel(os.path.join(DATA_PATH, \"_DOCS/seizures_v36r.xlsx\"), sheet_name=\"train\", usecols='A:O', index_col=0)\n",
    "ref_dev = pd.read_excel(os.path.join(DATA_PATH, \"_DOCS/seizures_v36r.xlsx\"), sheet_name=\"dev\", usecols='A:O', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_train.rename(columns={\"Unnamed: 11\": \"Filename\", \"Seizure Time\": \"Start Time\", \"Unnamed: 13\": \"Stop Time\"}, inplace=True)\n",
    "ref_train = ref_train.iloc[1: , :]\n",
    "ref_train = ref_train.dropna(subset=[\"Start Time\", \"Stop Time\", \"Seizure Type\"])\n",
    "ref_dev.rename(columns={\"Unnamed: 11\": \"Filename\", \"Seizure Time\": \"Start Time\", \"Unnamed: 13\": \"Stop Time\"}, inplace=True)\n",
    "ref_dev = ref_dev.iloc[1: , :]\n",
    "ref_dev = ref_dev.dropna(subset=[\"Start Time\", \"Stop Time\", \"Seizure Type\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Signal_list = [\"EEG FP1\", \n",
    "               \"EEG FP2\", \n",
    "               \"EEG F3\", \n",
    "               \"EEG F4\", \n",
    "               \"EEG C3\", \n",
    "               \"EEG C4\", \n",
    "               \"EEG P3\", \n",
    "               \"EEG P4\", \n",
    "               \"EEG O1\", \n",
    "               \"EEG O2\", \n",
    "               \"EEG F7\", \n",
    "               \"EEG F8\",\n",
    "               \"EEG T3\", \n",
    "               \"EEG T4\", \n",
    "               \"EEG T5\", \n",
    "               \"EEG T6\", \n",
    "               \"EEG FZ\", \n",
    "               \"EEG CZ\", \n",
    "               \"EEG PZ\"]\n",
    "n_signal = len(Signal_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_single_graph(start_time, f, ch_names):\n",
    "    Graph = nx.Graph()\n",
    "    f_temp = f.copy()\n",
    "    f_temp.crop(start_time, start_time + SLIDING_WINDOW, include_tmax=False)\n",
    "    data = f_temp.get_data()\n",
    "    Graph_attributes = []\n",
    "    for signal in Signal_list:\n",
    "        index = np.where(ch_names == signal)[0][0]\n",
    "        Graph_attributes.append((signal, {\"Signal\": data[index,:]}))\n",
    "    Graph.add_nodes_from(Graph_attributes)\n",
    "    for node1 in Graph.nodes():\n",
    "        for node2 in Graph.nodes():\n",
    "            if node1 == node2:\n",
    "                continue\n",
    "            Graph.add_edge(node1, node2)\n",
    "    Signals = nx.get_node_attributes(Graph, \"Signal\")\n",
    "    edge_attrib = {}\n",
    "    for edge in Graph.edges():\n",
    "        node1, node2 = edge\n",
    "        signal1 = Signals[node1]\n",
    "        signal2 = Signals[node2]\n",
    "        coeff_pearsonr, _ = scipy.stats.pearsonr(signal1, signal2)\n",
    "        norm_ccorr = np.sum(signal1*signal2) / (np.sqrt(np.sum(signal1**2)*np.sum(signal2**2)))\n",
    "        edge_attrib[edge] = {\"pearsonr\": np.abs(coeff_pearsonr), \"norm cross correlation\": np.abs(norm_ccorr)}\n",
    "    nx.set_edge_attributes(Graph, edge_attrib)\n",
    "    return Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = lambda a, i: a[0: i] if a.shape[0] > i else np.hstack((a, np.zeros(i - a.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_graph(Graph_list):\n",
    "    #Initialize the parameters of the new graph\n",
    "    Graph_combined = nx.Graph()\n",
    "    Signals_combined = {}\n",
    "    Edges_combined = {}\n",
    "    for name in Signal_list:\n",
    "        Signals_combined[name] = np.array([])\n",
    "    Graph = Graph_list[0]\n",
    "    for edge in Graph.edges():\n",
    "        Edges_combined[edge] = {\"pearsonr\": [], \"norm cross correlation\": []}\n",
    "\n",
    "    #Combine the sliding windows\n",
    "    for g in Graph_list:\n",
    "        Signals = nx.get_node_attributes(g, \"Signal\")\n",
    "        for name, item in Signals.items():\n",
    "            Signals_combined[name] = np.concatenate((Signals_combined[name], Signals[name]), axis=0)\n",
    "\n",
    "        for node1, node2, attributes in g.edges.data():\n",
    "            edge = (node1, node2)\n",
    "            Edges_combined[edge][\"pearsonr\"].append(attributes[\"pearsonr\"])\n",
    "            Edges_combined[edge][\"norm cross correlation\"].append(attributes[\"norm cross correlation\"])\n",
    "\n",
    "    #Truncate or pad with 0 to match sequence length\n",
    "    Graph_attributes = []\n",
    "    for name in Signal_list:\n",
    "        combined_signal = pad(Signals_combined[name], RESAMPLE_RATE * SLIDING_WINDOW * MAX_SEQUENCE_LENGTH)\n",
    "        Graph_attributes.append((name, {\"Signal\": combined_signal}))\n",
    "\n",
    "    for edge in Edges_combined:\n",
    "        Edges_combined[edge][\"pearsonr\"] = pad(np.array(Edges_combined[edge][\"pearsonr\"]), MAX_SEQUENCE_LENGTH)\n",
    "        Edges_combined[edge][\"norm cross correlation\"] = pad(np.array(Edges_combined[edge][\"norm cross correlation\"]), MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "    Graph_combined.add_nodes_from(Graph_attributes)\n",
    "    Graph_combined.add_edges_from(Edges_combined)\n",
    "    nx.set_edge_attributes(Graph_combined, Edges_combined)\n",
    "    return Graph_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for index, row in tqdm(ref_train.iterrows(), total=len(ref_train)):\n",
    "    start_time = row[\"Start Time\"]\n",
    "    stop_time = row[\"Stop Time\"]\n",
    "    seizure_type = row[\"Seizure Type\"]\n",
    "    path_file = os.path.join(DATA_PATH, \"edf/\", row[\"Filename\"])\n",
    "    file_name = path_file[:-3]+\"edf\"\n",
    "    file_code = file_name.split(sep=\"/\")[-1][:-4]\n",
    "\n",
    "    with mne.io.read_raw_edf(file_name, verbose=False) as f:\n",
    "        if f.info['sfreq'] != RESAMPLE_RATE:\n",
    "            f.resample(RESAMPLE_RATE)  #Set the same frequency to all EEGs\n",
    "        ch_names = [x.split(\"-\")[0] for x in f.ch_names]\n",
    "        ch_names = np.array(ch_names)\n",
    "\n",
    "        ### Run sliding window and construct a sequence\n",
    "        compteur = 0\n",
    "        Graph_list = []\n",
    "        while start_time + SLIDING_WINDOW < stop_time:\n",
    "            Graph = create_single_graph(start_time=start_time, f=f, ch_names=ch_names)\n",
    "            Graph_list.append(Graph)\n",
    "            start_time += SLIDING_WINDOW\n",
    "            compteur += 1\n",
    "            if compteur == MAX_SEQUENCE_LENGTH:\n",
    "                break\n",
    "        Combined_graph = combine_graph(Graph_list)\n",
    "        to_picle = (seizure_type, Combined_graph)\n",
    "        with open(f\"data_processed/train/{i}.pickle\", \"wb\") as f:\n",
    "            pickle.dump(to_picle, f)\n",
    "            i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in tqdm(ref_dev.iterrows(), total=len(ref_dev)):\n",
    "    start_time = row[\"Start Time\"]\n",
    "    stop_time = row[\"Stop Time\"]\n",
    "    seizure_type = row[\"Seizure Type\"]\n",
    "    path_file = os.path.join(DATA_PATH, \"edf/\", row[\"Filename\"])\n",
    "    file_name = path_file[:-3]+\"edf\"\n",
    "    file_code = file_name.split(sep=\"/\")[-1][:-4]\n",
    "\n",
    "    with mne.io.read_raw_edf(file_name, verbose=False) as f:\n",
    "        if f.info['sfreq'] != RESAMPLE_RATE:\n",
    "            f.resample(RESAMPLE_RATE)  #Set the same frequency to all EEGs\n",
    "        ch_names = [x.split(\"-\")[0] for x in f.ch_names]\n",
    "        ch_names = np.array(ch_names)\n",
    "\n",
    "        ### Run sliding window and construct a sequence\n",
    "        compteur = 0\n",
    "        Graph_list = []\n",
    "        while start_time + SLIDING_WINDOW < stop_time:\n",
    "            Graph = create_single_graph(start_time=start_time, f=f, ch_names=ch_names)\n",
    "            Graph_list.append(Graph)\n",
    "            start_time += SLIDING_WINDOW\n",
    "            compteur += 1\n",
    "            if compteur == MAX_SEQUENCE_LENGTH:\n",
    "                break\n",
    "        Combined_graph = combine_graph(Graph_list)\n",
    "        to_picle = (seizure_type, Combined_graph)\n",
    "        with open(f\"data_processed/dev/{i}.pickle\", \"wb\") as f:\n",
    "            pickle.dump(to_picle, f)\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.make_archive(\"data_processed\", 'zip', \"data_processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7fe33ad88930b679bfa056e9858ff209dfc89b38dfe6aa07887082d3e1ea3e57"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
